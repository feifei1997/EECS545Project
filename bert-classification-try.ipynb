{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom transformers import BertTokenizer\nimport torch\nfrom torch import nn\nfrom transformers import BertModel\nimport numpy as np\nfrom torch.optim import Adam\nfrom tqdm import tqdm\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nimport os\n\ndf = pd.read_csv(\"/kaggle/input/feedback-prize-2021/train.csv\")\ndf\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-19T22:45:37.928110Z","iopub.execute_input":"2022-02-19T22:45:37.929190Z","iopub.status.idle":"2022-02-19T22:45:41.171112Z","shell.execute_reply.started":"2022-02-19T22:45:37.929066Z","shell.execute_reply":"2022-02-19T22:45:41.170386Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"labels = {'Lead':0,\n          'Position':1,\n          'Claim':2,\n          'Concluding Statement':3,\n          'Evidence':4,\n          'Counterclaim':5,\n          'Rebuttal':6\n          }\nprev_label = {'Lead':0,\n          'Position':1,\n          'Claim':2,\n          'Concluding Statement':3,\n          'Evidence':4,\n          'Counterclaim':5,\n          'Rebuttal':6,\n          'Start':7\n          }","metadata":{"execution":{"iopub.status.busy":"2022-02-19T22:45:41.172875Z","iopub.execute_input":"2022-02-19T22:45:41.173872Z","iopub.status.idle":"2022-02-19T22:45:41.179475Z","shell.execute_reply.started":"2022-02-19T22:45:41.173827Z","shell.execute_reply":"2022-02-19T22:45:41.178687Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"sequence = df['predictionstring']\nsequence = sequence.apply(lambda x: x.split())\nsequence = sequence.apply(lambda x: list(map(int, x)))\nsequence\ndf_new = df\nstart, end = [],[]\nfor i in range(len(sequence)):\n    start.append(sequence[i][0])\n    end.append(sequence[i][-1])\ndf_new['Start'] = start\ndf_new['End'] = end\n\nprev = [7]\n\nfor i in range(1, len(sequence)):\n    if df_new['End'][i-1] < df_new['Start'][i]:\n        prev.append(prev_label[df['discourse_type'][i-1]])\n    else:\n        prev.append(7)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T22:45:41.180846Z","iopub.execute_input":"2022-02-19T22:45:41.181324Z","iopub.status.idle":"2022-02-19T22:45:48.327171Z","shell.execute_reply.started":"2022-02-19T22:45:41.181285Z","shell.execute_reply":"2022-02-19T22:45:48.326461Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df_new['one_hot'] = prev\ndf_new","metadata":{"execution":{"iopub.status.busy":"2022-02-19T22:45:48.328306Z","iopub.execute_input":"2022-02-19T22:45:48.328563Z","iopub.status.idle":"2022-02-19T22:45:48.408150Z","shell.execute_reply.started":"2022-02-19T22:45:48.328529Z","shell.execute_reply":"2022-02-19T22:45:48.407412Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n\n    def __init__(self, df):\n\n        self.labels = [labels[label] for label in df['discourse_type']]\n        self.texts = [tokenizer(text, \n                               padding='max_length', max_length = 256, truncation=True,\n                                return_tensors=\"pt\") for text in df['discourse_text']]\n        self.prev = [one_hot for one_hot in df['one_hot']]\n\n    def classes(self):\n        return self.labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def get_batch_labels(self, idx):\n        # Fetch a batch of labels\n        return np.array(self.labels[idx])\n\n    def get_batch_texts(self, idx):\n        # Fetch a batch of inputs\n        return self.texts[idx]\n\n    def get_batch_prev(self, idx):\n        return self.prev[idx]\n    \n    def __getitem__(self, idx):\n\n        batch_texts = self.get_batch_texts(idx)\n        batch_prev = self.get_batch_prev(idx)\n        batch_y = self.get_batch_labels(idx)\n\n        return batch_texts, batch_prev, batch_y","metadata":{"execution":{"iopub.status.busy":"2022-02-19T22:45:48.410171Z","iopub.execute_input":"2022-02-19T22:45:48.411901Z","iopub.status.idle":"2022-02-19T22:45:48.428736Z","shell.execute_reply.started":"2022-02-19T22:45:48.411855Z","shell.execute_reply":"2022-02-19T22:45:48.427926Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class BertClassifier(nn.Module):\n\n    def __init__(self, dropout=0.5):\n\n        super(BertClassifier, self).__init__()\n\n        self.bert = BertModel.from_pretrained('bert-base-cased')\n        self.dropout = nn.Dropout(dropout)\n        self.linear = nn.Linear(768, 7)\n        self.linear_2 = nn.Linear(15,7)\n        self.relu = nn.ReLU()\n\n    def forward(self, input_id, mask, prev_identity):\n        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n        dropout_output = self.dropout(pooled_output)\n        linear_output = self.linear(dropout_output)\n        linear_output = torch.cat((linear_output, prev_identity), 1)\n        #print(linear_output)\n        linear_output = self.linear_2(linear_output)\n        final_layer = self.relu(linear_output)\n\n        return final_layer\n","metadata":{"execution":{"iopub.status.busy":"2022-02-19T23:27:17.448382Z","iopub.execute_input":"2022-02-19T23:27:17.449069Z","iopub.status.idle":"2022-02-19T23:27:17.458651Z","shell.execute_reply.started":"2022-02-19T23:27:17.449013Z","shell.execute_reply":"2022-02-19T23:27:17.457537Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n\nprint(len(df[:70000]))\n","metadata":{"execution":{"iopub.status.busy":"2022-02-19T22:45:48.443757Z","iopub.execute_input":"2022-02-19T22:45:48.444261Z","iopub.status.idle":"2022-02-19T22:45:53.247204Z","shell.execute_reply.started":"2022-02-19T22:45:48.444196Z","shell.execute_reply":"2022-02-19T22:45:53.246427Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"np.random.seed(112)\ndf_new_new = df[:70000]\ndf_train, df_val, df_test = np.split(df_new_new.sample(frac=1, random_state=42), \n                                     [int(.8*len(df_new_new)), int(.9*len(df_new_new))])\n\nprint(len(df_train),len(df_val), len(df_test))","metadata":{"execution":{"iopub.status.busy":"2022-02-19T22:45:53.248372Z","iopub.execute_input":"2022-02-19T22:45:53.249873Z","iopub.status.idle":"2022-02-19T22:45:53.293989Z","shell.execute_reply.started":"2022-02-19T22:45:53.249830Z","shell.execute_reply":"2022-02-19T22:45:53.293277Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2022-02-19T23:21:36.179374Z","iopub.execute_input":"2022-02-19T23:21:36.179689Z","iopub.status.idle":"2022-02-19T23:21:36.188407Z","shell.execute_reply.started":"2022-02-19T23:21:36.179655Z","shell.execute_reply":"2022-02-19T23:21:36.187666Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def train(model, train_data, val_data, learning_rate, epochs):\n\n    train, val = Dataset(train_data), Dataset(val_data)\n\n    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = Adam(model.parameters(), lr= learning_rate)\n\n    if use_cuda:\n\n            model = model.cuda()\n            criterion = criterion.cuda()\n\n    for epoch_num in range(epochs):\n\n            total_acc_train = 0\n            total_loss_train = 0\n\n            for train_input, prev ,train_label in tqdm(train_dataloader):\n\n                train_label = train_label.to(device)\n                train_label=train_label.to(torch.int64)\n                mask = train_input['attention_mask'].to(device)\n                input_id = train_input['input_ids'].squeeze(1).to(device)\n                prev = torch.nn.functional.one_hot(prev, num_classes=8).to(device)\n\n                output = model(input_id, mask, prev)\n                \n                batch_loss = criterion(output, train_label)\n                total_loss_train += batch_loss.item()\n                \n                acc = (output.argmax(dim=1) == train_label).sum().item()\n                total_acc_train += acc\n\n                model.zero_grad()\n                batch_loss.backward()\n                optimizer.step()\n            \n            total_acc_val = 0\n            total_loss_val = 0\n\n            with torch.no_grad():\n\n                for val_input, prev_val ,val_label in val_dataloader:\n\n                    val_label = val_label.to(device)\n                    mask = val_input['attention_mask'].to(device)\n                    input_id = val_input['input_ids'].squeeze(1).to(device)\n                    prev_val = torch.nn.functional.one_hot(prev_val, num_classes=8).to(device)\n\n                    output = model(input_id, mask, prev)\n\n                    batch_loss = criterion(output, val_label)\n                    total_loss_val += batch_loss.item()\n                    \n                    acc = (output.argmax(dim=1) == val_label).sum().item()\n                    total_acc_val += acc\n            \n            print(\n                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n                  \nEPOCHS = 4\nmodel = BertClassifier()\nLR = 1e-6\n              \ntrain(model, df_train, df_val, LR, EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T23:27:22.628652Z","iopub.execute_input":"2022-02-19T23:27:22.629206Z","iopub.status.idle":"2022-02-20T02:07:27.588235Z","shell.execute_reply.started":"2022-02-19T23:27:22.629168Z","shell.execute_reply":"2022-02-20T02:07:27.586489Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, test_data):\n\n    test = Dataset(test_data)\n\n    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    if use_cuda:\n\n        model = model.cuda()\n\n    total_acc_test = 0\n    with torch.no_grad():\n\n        for test_input, prev, test_label in test_dataloader:\n            \n            test_label = test_label.to(device)\n            mask = test_input['attention_mask'].to(device)\n            input_id = test_input['input_ids'].squeeze(1).to(device)\n            prev = torch.nn.functional.one_hot(prev, num_classes=8).to(device)\n            \n            output = model(input_id, mask, prev)\n\n            acc = (output.argmax(dim=1) == test_label).sum().item()\n            total_acc_test += acc\n    \n    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n    \nevaluate(model, df_test)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T02:57:08.926522Z","iopub.execute_input":"2022-02-20T02:57:08.926930Z","iopub.status.idle":"2022-02-20T02:58:28.469202Z","shell.execute_reply.started":"2022-02-20T02:57:08.926894Z","shell.execute_reply":"2022-02-20T02:58:28.467595Z"},"trusted":true},"execution_count":21,"outputs":[]}]}